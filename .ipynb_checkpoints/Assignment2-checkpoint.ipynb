{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_data.csv\")\n",
    "test = pd.read_csv(\"test_data.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Bad Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HOSPITAL BEDS Some aspects of the city's prepa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>END APMGPURUWUPUGPB</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>END NRAFLFVEFEIRFII</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In a separate transaction, VW said it will pay...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>B 1 B 2: Financial Instruments with similar ec...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3995</th>\n",
       "      <td>By Chris Wack Aurora Cannabis Inc. shares were...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3996</th>\n",
       "      <td>Details of any open stock settled derivative p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3997</th>\n",
       "      <td>People want to know what ‚Äôs happening, and w...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3998</th>\n",
       "      <td>Forward looking statements include any stateme...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3999</th>\n",
       "      <td>Industrial &amp; commercial accounted for 52% of B...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence  Bad Sentence\n",
       "0     HOSPITAL BEDS Some aspects of the city's prepa...             0\n",
       "1                                   END APMGPURUWUPUGPB             1\n",
       "2                                   END NRAFLFVEFEIRFII             1\n",
       "3     In a separate transaction, VW said it will pay...             0\n",
       "4     B 1 B 2: Financial Instruments with similar ec...             1\n",
       "...                                                 ...           ...\n",
       "3995  By Chris Wack Aurora Cannabis Inc. shares were...             0\n",
       "3996  Details of any open stock settled derivative p...             1\n",
       "3997  People want to know what ‚Äôs happening, and w...             0\n",
       "3998  Forward looking statements include any stateme...             1\n",
       "3999  Industrial & commercial accounted for 52% of B...             0\n",
       "\n",
       "[4000 rows x 2 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Bad Sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The performance of a benchmark shall not be in...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No media Q&amp;A.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PARIS, March 25( Reuters) - Essilor Luxottica ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\" For over two decades Exela has been providin...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.................................................</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>AMEX RESUMED INVSCO ADV MPLII &lt; VKI.A &gt;</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>Short Link: https://tmsnrt.rs/37e DHOk Video T...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>Following is a list of Massachusetts drivers i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>Changes in the rates of exchange between curre...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>\" If you look at the Highlanders, guys like( f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence  Bad Sentence\n",
       "0    The performance of a benchmark shall not be in...             0\n",
       "1                                        No media Q&A.             0\n",
       "2    PARIS, March 25( Reuters) - Essilor Luxottica ...             0\n",
       "3    \" For over two decades Exela has been providin...             0\n",
       "4    .................................................             1\n",
       "..                                                 ...           ...\n",
       "995            AMEX RESUMED INVSCO ADV MPLII < VKI.A >             1\n",
       "996  Short Link: https://tmsnrt.rs/37e DHOk Video T...             1\n",
       "997  Following is a list of Massachusetts drivers i...             0\n",
       "998  Changes in the rates of exchange between curre...             1\n",
       "999  \" If you look at the Highlanders, guys like( f...             0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import utils\n",
    "import gensim.parsing.preprocessing as gsp\n",
    "\n",
    "filters = [\n",
    "           gsp.strip_tags, \n",
    "           gsp.strip_punctuation,\n",
    "           gsp.strip_multiple_whitespaces,\n",
    "           gsp.strip_numeric,\n",
    "           gsp.remove_stopwords, \n",
    "           gsp.strip_short, \n",
    "           gsp.stem_text\n",
    "          ]\n",
    "\n",
    "def clean_text(s):\n",
    "    s = s.lower()\n",
    "    s = utils.to_unicode(s)\n",
    "    for f in filters:\n",
    "        s = f(s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hospit bed aspect citi prepared remain unknown'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_text(train.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x = train['Sentence']\n",
    "df_y = train['Bad Sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       HOSPITAL BEDS Some aspects of the city's prepa...\n",
       "1                                     END APMGPURUWUPUGPB\n",
       "2                                     END NRAFLFVEFEIRFII\n",
       "3       In a separate transaction, VW said it will pay...\n",
       "4       B 1 B 2: Financial Instruments with similar ec...\n",
       "                              ...                        \n",
       "3995    By Chris Wack Aurora Cannabis Inc. shares were...\n",
       "3996    Details of any open stock settled derivative p...\n",
       "3997    People want to know what ‚Äôs happening, and w...\n",
       "3998    Forward looking statements include any stateme...\n",
       "3999    Industrial & commercial accounted for 52% of B...\n",
       "Name: Sentence, Length: 4000, dtype: object"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       1\n",
       "2       1\n",
       "3       0\n",
       "4       1\n",
       "       ..\n",
       "3995    0\n",
       "3996    1\n",
       "3997    0\n",
       "3998    1\n",
       "3999    0\n",
       "Name: Bad Sentence, Length: 4000, dtype: int64"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text2TfIdfTransformer(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self._model = TfidfVectorizer()\n",
    "        pass\n",
    "\n",
    "    def fit(self, df_x, df_y=None):\n",
    "        df_x = df_x.apply(lambda x : clean_text(x))\n",
    "        self._model.fit(df_x)\n",
    "        return self\n",
    "\n",
    "    def transform(self, df_x):\n",
    "        return self._model.transform(df_x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = Text2TfIdfTransformer()\n",
    "tfidf_vectors = tfidf_transformer.fit(df_x).transform(df_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 8164)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7617)\t0.7924099539714787\n",
      "  (0, 5953)\t0.6099889055113372\n",
      "  (1, 2294)\t0.39479173280371993\n",
      "  (1, 334)\t0.9187706393381517\n",
      "  (2, 4963)\t0.9187706393381517\n",
      "  (2, 2294)\t0.39479173280371993\n",
      "  (3, 7960)\t0.35176664119633005\n",
      "  (3, 7192)\t0.2625150460459242\n",
      "  (3, 6310)\t0.16800984223155385\n",
      "  (3, 4318)\t0.26824633954733523\n",
      "  (3, 3722)\t0.35176664119633005\n",
      "  (3, 3515)\t0.3691695866271746\n",
      "  (3, 3245)\t0.2293290057097024\n",
      "  (3, 3094)\t0.3691695866271746\n",
      "  (3, 1356)\t0.35176664119633005\n",
      "  (3, 738)\t0.2165706895470998\n",
      "  (3, 730)\t0.2960001882516001\n",
      "  (4, 8053)\t0.379335416025381\n",
      "  (4, 7531)\t0.2859929595125821\n",
      "  (4, 6623)\t0.32279706414257475\n",
      "  (4, 6505)\t0.31924221338475905\n",
      "  (4, 5335)\t0.25448820820448337\n",
      "  (4, 5097)\t0.34608616215320404\n",
      "  (4, 4973)\t0.19192185303476203\n",
      "  (4, 3611)\t0.28773746207666034\n",
      "  :\t:\n",
      "  (3996, 6454)\t0.2176101993868852\n",
      "  (3996, 5097)\t0.6534068761890128\n",
      "  (3996, 5079)\t0.4755743969808578\n",
      "  (3996, 5067)\t0.37111738028976304\n",
      "  (3996, 2931)\t0.2852119313163929\n",
      "  (3996, 2716)\t0.24023547216577315\n",
      "  (3997, 7932)\t0.7912595648837292\n",
      "  (3997, 7857)\t0.2945633859613719\n",
      "  (3997, 3951)\t0.30612317093369323\n",
      "  (3997, 3722)\t0.3769794825145145\n",
      "  (3997, 2640)\t0.22652988017383727\n",
      "  (3998, 7960)\t0.22647402965017877\n",
      "  (3998, 7165)\t0.15559596974640655\n",
      "  (3998, 6623)\t0.18595427190185415\n",
      "  (3998, 5549)\t0.19320426691615722\n",
      "  (3998, 5097)\t0.7974818540490926\n",
      "  (3998, 5067)\t0.22647402965017877\n",
      "  (3998, 2725)\t0.15164161870304638\n",
      "  (3998, 1475)\t0.22647402965017877\n",
      "  (3998, 948)\t0.19937046351227314\n",
      "  (3998, 410)\t0.22647402965017877\n",
      "  (3999, 3515)\t0.5707355641866427\n",
      "  (3999, 3115)\t0.40584782262633523\n",
      "  (3999, 2633)\t0.42872995744940895\n",
      "  (3999, 727)\t0.5707355641866427\n"
     ]
    }
   ],
   "source": [
    "print(tfidf_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl_xgb_tf_idf = Pipeline(steps=[('tfidf',Text2TfIdfTransformer()),\n",
    "                         ('xgboost', xgb.XGBClassifier(objective='binary:hinge'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {\n",
    "    'n_estimators': [100, 150],\n",
    "    'max_depth': [7, 11, 15],\n",
    "    'learning_rate': [0.1]\n",
    "}\n",
    "\n",
    "pl_xgb_tf_idf = Pipeline(steps=[('tfidf',Text2TfIdfTransformer()),\n",
    "                         ('xgboost', GridSearchCV(xgb.XGBClassifier(objective='binary:hinge'),\n",
    "                                                  param_grid=param,\n",
    "                                                   cv=5,\n",
    "                                                   n_jobs=-1,\n",
    "                                                   scoring=f1_score\n",
    "                                                 ))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [nan nan nan nan nan nan]\n",
      "  warnings.warn(\n",
      "/opt/miniconda3/lib/python3.8/site-packages/xgboost/sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# clf = GridSearchCV(estimator=pl_xgb_tf_idf,\n",
    "#                    param_grid={},\n",
    "#                    cv=10,\n",
    "#                    n_jobs=-1,\n",
    "#                    scoring=f1_score)\n",
    "cv_fit = pl_xgb_tf_idf.fit(df_x, df_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       1\n",
       "2       1\n",
       "3       0\n",
       "4       1\n",
       "       ..\n",
       "3995    0\n",
       "3996    1\n",
       "3997    0\n",
       "3998    1\n",
       "3999    0\n",
       "Name: Bad Sentence, Length: 4000, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', Text2TfIdfTransformer()),\n",
       "                ('xgboost',\n",
       "                 GridSearchCV(cv=5,\n",
       "                              estimator=XGBClassifier(base_score=None,\n",
       "                                                      booster=None,\n",
       "                                                      colsample_bylevel=None,\n",
       "                                                      colsample_bynode=None,\n",
       "                                                      colsample_bytree=None,\n",
       "                                                      gamma=None, gpu_id=None,\n",
       "                                                      importance_type='gain',\n",
       "                                                      interaction_constraints=None,\n",
       "                                                      learning_rate=None,\n",
       "                                                      max_delta_step=None,\n",
       "                                                      max_depth=None,\n",
       "                                                      min_child_weight=None,...\n",
       "                                                      n_estimators=100,\n",
       "                                                      n_jobs=None,\n",
       "                                                      num_parallel_tree=None,\n",
       "                                                      objective='binary:hinge',\n",
       "                                                      random_state=None,\n",
       "                                                      reg_alpha=None,\n",
       "                                                      reg_lambda=None,\n",
       "                                                      scale_pos_weight=None,\n",
       "                                                      subsample=None,\n",
       "                                                      tree_method=None,\n",
       "                                                      validate_parameters=None,\n",
       "                                                      verbosity=None),\n",
       "                              n_jobs=-1,\n",
       "                              param_grid={'learning_rate': [0.1],\n",
       "                                          'max_depth': [7, 11, 15],\n",
       "                                          'n_estimators': [100, 150]},\n",
       "                              scoring=<function f1_score at 0x7faf44d915e0>))])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'memory': None,\n",
       " 'steps': [('tfidf', Text2TfIdfTransformer()),\n",
       "  ('xgboost', GridSearchCV(cv=5,\n",
       "                estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                        colsample_bylevel=None,\n",
       "                                        colsample_bynode=None,\n",
       "                                        colsample_bytree=None, gamma=None,\n",
       "                                        gpu_id=None, importance_type='gain',\n",
       "                                        interaction_constraints=None,\n",
       "                                        learning_rate=None, max_delta_step=None,\n",
       "                                        max_depth=None, min_child_weight=None,\n",
       "                                        missing=nan, monotone_constraints=None,\n",
       "                                        n_estimators=100, n_jobs=None,\n",
       "                                        num_parallel_tree=None,\n",
       "                                        objective='binary:hinge',\n",
       "                                        random_state=None, reg_alpha=None,\n",
       "                                        reg_lambda=None, scale_pos_weight=None,\n",
       "                                        subsample=None, tree_method=None,\n",
       "                                        validate_parameters=None, verbosity=None),\n",
       "                n_jobs=-1,\n",
       "                param_grid={'learning_rate': [0.1], 'max_depth': [7, 11, 15],\n",
       "                            'n_estimators': [100, 150]},\n",
       "                scoring=<function f1_score at 0x7faf44d915e0>))],\n",
       " 'verbose': False,\n",
       " 'tfidf': Text2TfIdfTransformer(),\n",
       " 'xgboost': GridSearchCV(cv=5,\n",
       "              estimator=XGBClassifier(base_score=None, booster=None,\n",
       "                                      colsample_bylevel=None,\n",
       "                                      colsample_bynode=None,\n",
       "                                      colsample_bytree=None, gamma=None,\n",
       "                                      gpu_id=None, importance_type='gain',\n",
       "                                      interaction_constraints=None,\n",
       "                                      learning_rate=None, max_delta_step=None,\n",
       "                                      max_depth=None, min_child_weight=None,\n",
       "                                      missing=nan, monotone_constraints=None,\n",
       "                                      n_estimators=100, n_jobs=None,\n",
       "                                      num_parallel_tree=None,\n",
       "                                      objective='binary:hinge',\n",
       "                                      random_state=None, reg_alpha=None,\n",
       "                                      reg_lambda=None, scale_pos_weight=None,\n",
       "                                      subsample=None, tree_method=None,\n",
       "                                      validate_parameters=None, verbosity=None),\n",
       "              n_jobs=-1,\n",
       "              param_grid={'learning_rate': [0.1], 'max_depth': [7, 11, 15],\n",
       "                          'n_estimators': [100, 150]},\n",
       "              scoring=<function f1_score at 0x7faf44d915e0>),\n",
       " 'xgboost__cv': 5,\n",
       " 'xgboost__error_score': nan,\n",
       " 'xgboost__estimator__objective': 'binary:hinge',\n",
       " 'xgboost__estimator__use_label_encoder': True,\n",
       " 'xgboost__estimator__base_score': None,\n",
       " 'xgboost__estimator__booster': None,\n",
       " 'xgboost__estimator__colsample_bylevel': None,\n",
       " 'xgboost__estimator__colsample_bynode': None,\n",
       " 'xgboost__estimator__colsample_bytree': None,\n",
       " 'xgboost__estimator__gamma': None,\n",
       " 'xgboost__estimator__gpu_id': None,\n",
       " 'xgboost__estimator__importance_type': 'gain',\n",
       " 'xgboost__estimator__interaction_constraints': None,\n",
       " 'xgboost__estimator__learning_rate': None,\n",
       " 'xgboost__estimator__max_delta_step': None,\n",
       " 'xgboost__estimator__max_depth': None,\n",
       " 'xgboost__estimator__min_child_weight': None,\n",
       " 'xgboost__estimator__missing': nan,\n",
       " 'xgboost__estimator__monotone_constraints': None,\n",
       " 'xgboost__estimator__n_estimators': 100,\n",
       " 'xgboost__estimator__n_jobs': None,\n",
       " 'xgboost__estimator__num_parallel_tree': None,\n",
       " 'xgboost__estimator__random_state': None,\n",
       " 'xgboost__estimator__reg_alpha': None,\n",
       " 'xgboost__estimator__reg_lambda': None,\n",
       " 'xgboost__estimator__scale_pos_weight': None,\n",
       " 'xgboost__estimator__subsample': None,\n",
       " 'xgboost__estimator__tree_method': None,\n",
       " 'xgboost__estimator__validate_parameters': None,\n",
       " 'xgboost__estimator__verbosity': None,\n",
       " 'xgboost__estimator': XGBClassifier(base_score=None, booster=None, colsample_bylevel=None,\n",
       "               colsample_bynode=None, colsample_bytree=None, gamma=None,\n",
       "               gpu_id=None, importance_type='gain', interaction_constraints=None,\n",
       "               learning_rate=None, max_delta_step=None, max_depth=None,\n",
       "               min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "               n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
       "               objective='binary:hinge', random_state=None, reg_alpha=None,\n",
       "               reg_lambda=None, scale_pos_weight=None, subsample=None,\n",
       "               tree_method=None, validate_parameters=None, verbosity=None),\n",
       " 'xgboost__n_jobs': -1,\n",
       " 'xgboost__param_grid': {'n_estimators': [100, 150],\n",
       "  'max_depth': [7, 11, 15],\n",
       "  'learning_rate': [0.1]},\n",
       " 'xgboost__pre_dispatch': '2*n_jobs',\n",
       " 'xgboost__refit': True,\n",
       " 'xgboost__return_train_score': False,\n",
       " 'xgboost__scoring': <function sklearn.metrics._classification.f1_score(y_true, y_pred, *, labels=None, pos_label=1, average='binary', sample_weight=None, zero_division='warn')>,\n",
       " 'xgboost__verbose': 0}"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_fit.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
